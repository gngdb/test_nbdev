---

title: Title


keywords: fastai
sidebar: home_sidebar



nb_path: "index.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: index.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="https://badge.fury.io/py/llamass"><img src="https://badge.fury.io/py/llamass.svg" alt="PyPI version"></a></p>
<p><img src="https://github.com/gngdb/llamass/workflows/CI/badge.svg" alt="example workflow"></p>
<h1 id="llamass">llamass<a class="anchor-link" href="#llamass"> </a></h1><blockquote><p>A Light Loader for the <a href="https://amass.is.tue.mpg.de/">AMASS dataset</a> to make downloading and training on it easier.</p>
</blockquote>
<p>I'm writing this to use in a project working with pose data. I wanted to be able to install it in colab notebooks and elsewhere easily. Hopefully it's also useful for other people but be aware this is research code so not necessarily reliable.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To do:</p>
<ul>
<li><del>Note here about the dataset license</del></li>
<li><del>Instructions on how to download the dataset</del></li>
<li>Instructions on how to install the requirements for visualization</li>
<li>Augmentations pulled from original AMASS repo</li>
<li><del>Install nbqa and black, run on existing notebooks</del></li>
<li>Example train/test splits by unpacking different datasets to different locations</li>
<li><del>Add CC licensed picture of llamas to github preview</del></li>
<li><del>add to pypi</del></li>
<li><del>add badges</del></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Install">Install<a class="anchor-link" href="#Install"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="License-Agreement">License Agreement<a class="anchor-link" href="#License-Agreement"> </a></h3><p>Before using the AMASS dataset I'm expected to sign up to the license agreeement <a href="https://amass.is.tue.mpg.de/index.html">here</a>. This package doesn't require any other code from MPI but visualization of pose data does, see below.</p>
<h3 id="Install-with-pip">Install with pip<a class="anchor-link" href="#Install-with-pip"> </a></h3><p>Requirements are handled by pip during the install but in a new environment I would install <a href="https://pytorch.org/get-started/locally/">pytorch</a>
first to install it with cuda.</p>
<p><code>pip install llamass</code></p>
<h3 id="For-Visualization">For Visualization<a class="anchor-link" href="#For-Visualization"> </a></h3><p><strong>To do</strong>: provide script to install this and all its requirements (for curl into bash on colab would be nice)</p>
<ul>
<li><a href="https://github.com/nghorbani/human_body_prior">Human Body Prior</a>, licensed under the <a href="https://smpl-x.is.tue.mpg.de/">SMPL-X project</a></li>
<li><a href="https://github.com/nghorbani/body_visualizer">Body Visualizer</a>, licensed under the <a href="https://smpl-x.is.tue.mpg.de/">SMPL-X project</a></li>
<li>MAYBE <a href="https://github.com/MPI-IS/mesh">mesh</a>, does not require a sign up page</li>
</ul>
<p>For <a href="https://github.com/MPI-IS/mesh">MPI's mesh library</a>, <code>libboost-dev</code> is required:</p>

<pre><code>sudo apt-get install libboost-dev</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="How-to-use">How to use<a class="anchor-link" href="#How-to-use"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Downloading-the-data">Downloading the data<a class="anchor-link" href="#Downloading-the-data"> </a></h3><p>The <a href="https://amass.is.tue.mpg.de/index.html">AMASS website</a> provides links to download the various parts of the AMASS dataset. Each is provided as a <code>.tar.bz2</code> and I had to download them from the website by hand. Save all of these in a folder somehwere.</p>
<h3 id="Unpacking-the-data">Unpacking the data<a class="anchor-link" href="#Unpacking-the-data"> </a></h3><p>After installing <code>llamass</code> a console script is provided to unpack the <code>tar.bz2</code> files downloaded from the <a href="https://amass.is.tue.mpg.de/index.html">AMASS</a> website:</p>

<pre><code>fast_amass_unpack -n 4 &lt;.tar.bz2 directory&gt; &lt;directory to save unpacked data&gt;</code></pre>
<p>This will unpack the data in parallel in 4 jobs and provides a progress bar.</p>
<p>Alternatively, this can be access in the library using the <code>llamass.core.unpack_body_models</code> function:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">llamass.core</span>

<span class="n">llamass</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">unpack_body_models</span><span class="p">(</span><span class="s2">&quot;sample_data/&quot;</span><span class="p">,</span> <span class="n">unpacked_directory</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>sample_data/sample.tar.bz2 extracting to /tmp/tmp2mpzo7r2
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Using-the-data">Using the data<a class="anchor-link" href="#Using-the-data"> </a></h3><p>Once the data is unpacked it can be loaded by a PyTorch DataLoader directly using the <code>llamass.core.AMASS</code> Dataset class.</p>
<ul>
<li><code>overlapping</code>: whether the clips of frames taken from each file should be allowed to overlap</li>
<li><code>clip_length</code>: how long should clips from each file be?</li>
<li><code>transform</code>: a transformation function apply to all fields</li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>

<span class="n">amass</span> <span class="o">=</span> <span class="n">llamass</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">AMASS</span><span class="p">(</span>
    <span class="n">unpacked_directory</span><span class="p">,</span> <span class="n">overlapping</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">clip_length</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">amassloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">amass</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">amassloader</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
    <span class="k">break</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>poses torch.Size([4, 1, 156])
dmpls torch.Size([4, 1, 8])
trans torch.Size([4, 1, 3])
betas torch.Size([4, 1, 16])
gender torch.Size([4, 1])
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Future-Work">Future Work<a class="anchor-link" href="#Future-Work"> </a></h2><p>Caching the dataset may be easy to implement with <a href="https://joblib.readthedocs.io/en/latest/generated/joblib.Memory.html">joblib's Memory</a> so I'm looking into this.</p>

</div>
</div>
</div>
</div>
 

